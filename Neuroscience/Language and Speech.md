[People solve rebuses unwittingly—Both forward and backward: Empirical evidence for the mental effectiveness of the signifier](https://doi.org/10.3389/fnhum.2022.965183) #oly23 (2023)

- two images were presented side-by-side whose individual French names together formed a composite word with a completely different semantic meaning
- example:
    - **paon** /pã/ (peacock)
    - **terre** /tεr/ (earth)
        - together form the French word **panthère** /pãtεr/ (panther)
- after looking at them for 4 seconds, the participants were given a target word--for the above example, **félin** (cat)--and were asked to write the first 6 words that came to mind when considering it
- researchers tested to see if one of the 6 words was the combined word (**panthère**) to show that people solve rebus puzzles unwittingly (a higher incidence of associating to the rebus (combined word) compared to control groups)

![[oly23 fig 2 - paon and terre forming panthere.png]]

The intro emphasizes the importance and influence not of the *semantic* meaning of a word (what it means) but the *phonological* dimension: simply how it sounds irrespective to its meaning.  "... the black beetle is supposed to induce anxiety upon Mr. E. not solely through the black, erratic appearance of its [being a] beetle, but ... through the linguistic structure of its name, *Käfer*, referring to the anxiogenic ambivalent choice of Mr. E’s mother for Mr. E’s father: *Que faire?* (“What to do now?”)." (The patient in question knew both German and French) p. 3

- total of 14 target words. 7 were presented with their corresponding rebus images, 7 with random images from a separate pool of them to act as a control
- in half the experiments the images were forward (*paon* to the left of *terre*) and the other half backwards (*terre* to the left of *paon*) p. 8
- participants were screened out if they "caught on" to the nature of the experiment and what was being tested. a post-experiment survey was applied to test for awareness of the protocol (the hypothesis is that people solve rebuses strictly *unwittingly*). this left 436 (of 788) valid participants' results for analysis

## Results

- "The analysis of the fixed effects ... shows a significant effect of the condition [experiment vs control] on [rebus resolution] score." p. 10
- "The variation (FW-RV) value is non-significant." (!!) this means even if the second syllable comes before the first the effect is still there
- a second experiment was almost identical but showed only one of the words *paon* or *terre*, not both of them, to ensure the effect was from compositing the two phonological effects together

## Discussion

"Our results show that people solve rebuses unwittingly, with images presented both in forward and reverse order (Experiment 1), and that this rebus resolution is not the result of phonological priming by just one of both images (Experiment 2). Therefore, the rebus resolution must be the result of the simultaneous presentation of both images, and this in agreement with the fact that a rebus, indeed, implies the condensation of the two names of the images, following Freud’s ... definition of condensation: “Condensation is brought about ... by latent elements which [are] fused into a single unity”." p. 13

"Remarkably, the rebus resolution works as well both in forward and in backward (reverse) presentation of the two images. We did expect this result as we proposed that rebus resolution is carried by the Freudian primary process, which works independently of spatial configuration." p. 13

"... the relevance of these findings might be especially important in clinical situations: indeed, they might offer a rational ground for phenomena and their interpretation, which at first sight might seem completely “crazy” ... Our results contribute to the idea that the rebus principle is a general principle for mental functioning, and thereby helps to understand phenomena described here." p. 16

"In sum, our results with a supraliminal rebus paradigm show inadvertent rebus resolution of the visual environment as well as unwitting rebus resolution independently of image order, and show that this rebus solving is not due to the phonological priming by one of both images, but the result of a condensation of the names of both depicted objects." p. 18

---

[Parallel processing in speech perception with local and global representations of linguistic context](https://doi.org/10.7554/eLife.72056) #bro22 (2022)

"Thus, there is little doubt that the brain uses context to facilitate processing of upcoming input, at multiple levels of representation. Here we investigate a fundamental question about the underlying cognitive organization: Does the brain develop a single, unified representation of the input? In other words, one representation that is consistent across hierarchical levels, effectively propagating information from the sentence context across hierarchical levels to anticipate even low-level features of the sensory input such as phonemes? Or do cognitive subsystems differ in the extent and kind of context they use to interpret their input?" p. 3

![[bro22 fig 1 - local and unified architectures.png]]

**Figure 1** Information flow in local and unified architectures for speech processing


## Discussion

"The present MEG data provide clear evidence for the existence of a neural representation of speech that is unified across representational hierarchies. This representation incrementally integrates phonetic input with information from the multi-word context within about 100 ms. However, in addition to this globally unified representation, brain responses also show evidence of separate neural representations that use more local contexts to process the same input." p. 19

"A second key result from this study, however, is evidence that this unified model is not the only representation of speech. Brain responses also exhibited evidence for two other, separate functional systems that process incoming phonemes while building representations that incorporate different, more constrained kinds of context: one based on a local word context, processing the current word with a prior based on context-independent lexical frequencies, and another based on the local phoneme sequence regardless of word boundaries. Each of these three functional systems generates its own predictions for upcoming phonemes, resulting in parallel responses to phoneme entropy. Each system is updated incrementally at the phoneme rate, reflected in early responses to surprisal. However, each system engages an at least partially different configuration of neural sources, as evidenced by the localization results."

"Together, these results suggest that multiple predictive models process speech input in parallel. An architecture consistent with these observations is sketched in Figure 8: three different neural systems receive the speech input in parallel. Each representation is updated incrementally by arriving phonemes. However, the three systems differ in the extent and kind of context that they incorporate, each generating its own probabilistic beliefs about the current word and/or future phonemes. For instance, the sublexical model uses the local phoneme history to predict upcoming phonemes. The updates are incremental because the state of the model at time $k+1$ is determined by the state of the model at time $k$ and the phoneme input from time $k$. The same incremental update pattern applies to the sublexical, word and sentence models."

![[bro22 fig 8 - parallel context models.png]]

**Figure 8** An architecture for speech perception with multiple parallel context models


### Implications for word recognition

"Perhaps the most surprising implication of our results is that multiple probabilistic cohort representations seem to be maintained in parallel." p. 21

"A second implication is that feedback from the sentence level context can and does affect phoneme processing. The observed phoneme entropy effects indicate that phoneme level expectations are modulated by the sentence context." p. 22


### Conclusions

"Prior research on the use of context during language processing has often focused on binary distinctions, such as asking whether context is or is not used to predict future input. Such questions assumed a single serial or cascaded processing stream. Here we show that this assumption might have been misleading, because different predictive models are maintained in parallel. Our results suggest that robust speech processing is based on probabilistic predictions using different context models in parallel, and cutting across hierarchical levels of representations." p. 23

---

[Visual and linguistic semantic representations are aligned at the border of human visual cortex](https://doi.org/10.1038/s41593-021-00921-6) (2021)
* Visual and linguistic representations are *aligned in the brain*
* "Remarkably, the pattern of semantic selectivity in these two distinct networks corresponded along the boundary of visual cortex: for visual categories represented posterior to the boundary, **the same categories were represented linguistically on the anterior side**. These results suggest that these two networks are smoothly joined to form one contiguous map." (Abstract)
